{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение или просто добавь воды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commitChanges():\n",
    "    ! git add KnowYourMemesParser.ipynb\n",
    "    ! git commit -m \"initial\"\n",
    "    ! git push -u origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 2c28403] initial\n",
      " 1 file changed, 510 insertions(+)\n",
      " create mode 100644 KnowYourMemesParser.ipynb\n",
      "Counting objects: 3, done.\n",
      "Delta compression using up to 4 threads.\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 6.38 KiB | 0 bytes/s, done.\n",
      "Total 3 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To https://github.com/DmitrySerg/memology.git\n",
      "   7791f1b..2c28403  master -> master\n",
      "Branch master set up to track remote branch master from origin.\n"
     ]
    }
   ],
   "source": [
    "commitChanges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a surprise tool that will help us later!\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Наш первый запрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для наших благородных исследовательских целей нужно собрать данные по каждому мему с соответствующей ему страницы. Но для начала нужно получить адреса этих страниц. Поэтому открываем основную страницу со всеми выложенными мемами. Выглядит она следующим образом:\n",
    "\n",
    "<img align=\"center\" src=\"pictures/memes_main.png\" height=\"500\" width=\"500\"> \n",
    "\n",
    "Отсюда мы и будем тащить ссылки на каждый из перечисленных мемов. Сохраним в переменную `page_link` адрес основной страницы и откроем её при помощи библиотеки `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_link = 'http://knowyourmeme.com/memes/all/page/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(page_link)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот и первая проблема! Обращаемся к [главному источнику знаний](https://en.wikipedia.org/wiki/HTTP_403) и выясняем, что 403-я ошибка выдается сервером, если он доступен и способен обрабатывать запросы, но по некоторым личным причинам отказывается это делать. Попробуем выяснить, почему. Для этого посмотрим, как выглядел финальный запрос, отправленный нами на сервер, а в первую очередь - как выглядел наш User-Agent в глазах сервера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Agent: python-requests/2.14.2\n",
      "Accept-Encoding: gzip, deflate\n",
      "Accept: */*\n",
      "Connection: keep-alive\n"
     ]
    }
   ],
   "source": [
    "for key, value in response.request.headers.items():\n",
    "    print(key+\": \"+value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, мы недвусмысленно дали понять серверу, что мы сидим на питоне и используем библиотеку requests под версией 2.14.2. Скорее всего, это вызвало у сервера некоторые подозрения относительно наших благих намерений и он решил нас безжалостно отвергнуть. Для сравнения, можно посмотреть, как выглядят request-headers у здорового человека:\n",
    "\n",
    "<img align=\"center\" src=\"pictures/good_headers.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "Очевидно, что нашему скромному запросу не тягаться с таким обилием мета-информации, которое передается при запросе из обычного браузера. К счастью, никто нам не мешает притвориться человечными и пустить пыль в глаза сервера при помощи генерации фейкового юзер-агента. Библиотек, которые справляются с такой задачей, существует очень и очень много, лично мне больше всего нравится [`fake-useragent`](https://pypi.python.org/pypi/fake-useragent). При вызове метода из различных кусочков будет генерироваться рандомное сочетание операционной системы, спецификаций и версии браузера, которые можно передавать в запрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserAgent().chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(page_link, headers={'User-Agent': UserAgent().chrome})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечательно, наша небольшая маскировка сработала и обманутый сервер покорно выдал благословенный 200 ответ — соединение установлено и данные получены, всё чудесно! Посмотрим, что же все-таки мы получили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html xmlns:fb=\\'http://www.facebook.com/2008/fbml\\' xmlns=\\'http://www.w3.org/1999/xhtml\\'>\\n<head>\\n<meta content=\\'text/html; charset=utf-8\\' http-equiv=\\'Content-Type\\'>\\n<script type=\"text/javascript\">window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\",\"licenseKey\":\"c1a6d52f38\",\"applicationID\":\"31165848\",\"transactionName\":\"dFdfRUpeWglTQB8GDUNKWFRLHlcJWg==\",\"queueTime\":0,\"applicationTime\":66,\"agent\":\"\"}</script>\\n<script type=\"text/javascript\">window.NREUM||(NREUM={}),__nr_require=function(e,n,t){function r(t){if(!n[t]){var o=n[t]={exports:{}};e[t][0].call(o.exports,function(n){var o=e[t][1][n];return r(o||n)},o,o.exports)}return n[t].exports}if(\"function\"==typeof __nr_require)return __nr_require;for(var o=0;o<t.length;o++)r(t[o]);return r}({1:[function(e,n,t){function r(){}function o(e,n,t){return function(){return i(e,[c.now()].concat(u(arguments)),n?null:this,t),n?void 0:this}}var i=e(\"handle\"),a=e(2),u=e(3),f=e(\"ee\").get(\"tracer\")'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит неудобоваримо, как насчет сварить из этого дела что-то покрасивее? Например, красивый суп."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Красивый суп\n",
    "\n",
    "<img align=\"center\" src=\"https://www.crummy.com/software/BeautifulSoup/10.1.jpg\" height=\"200\" width=\"200\"> \n",
    "\n",
    "Пакет **[bs4 , a.k.a BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)** (тут есть гиперссылка на лучшего друга человека — документацию) был назван в честь стишка про красивый суп из Алисы в стране чудес.\n",
    "\n",
    "Красивый суп. Эта совершенно волшебная библиотека, которая из сырого и необработанного HTML (или XML) кода страницы выдаст вам структурированный массив данных, по которому очень удобно искать необходимые теги, классы, атрибуты, тексты и прочие элементы веб страниц.\n",
    "\n",
    "> Пакет под названием `BeautifulSoup` — скорее всего, не то, что вам нужно. Это третья версия (*Beautiful Soup 3*), а мы будем использовать четвертую. Так что нам нужен пакет `beautifulsoup4`. Чтобы было совсем весело, при импорте нужно указывать другое название пакета — `bs4`, а импортировать функцию под названием `BeautifulSoup`. В общем, сначала легко запутаться, но эти трудности нужно преодолеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передадим функции `BeautifulSoup` текст веб-страницы, которую мы недавно получили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,'html.parser') # В опции также можно указать lxml, \n",
    "                                         # если предварительно установить одноименный пакет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим что-то вот такое:\n",
    "    \n",
    "```\n",
    "<!DOCTYPE html>\n",
    "\n",
    "<html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n",
    "<head>\n",
    "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
    "<script type=\"text/javascript\">window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"errorBeacon\":\"bam.nr-data.net\",\"licenseKey\":\"c1a6d52f38\",\"applicationID\":\"31165848\",\"transactionName\":\"dFdfRUpeWglTQB8GDUNKWFRLHkUNWUU=\",\"queueTime\":0,\"applicationTime\":24,\"agent\":\"\"}</script>\n",
    "<script type=\"text/javascript\">window.NREUM||(NREUM={}),__nr_require=function(e,n,t){function r(t){if(!n[t]){var o=n[t]={exports:{}};e[t][0].call(o.exports,function(n){var o=e[t][1][n];return r(o||n)},o,o.exports)}return n[t].exports}if(\"function\"==typeof __nr_require)return __nr_require;for(var o=0;o<t.length;o++)r(t[o]);return r}({1:[function(e,n,t){function r(){}function o(e,n,t){return function(){return i(e,[c.now()].concat(u(arguments)),n?null:this,t),n?void 0:this}}var i=e(\"handle\"),a=e(2),u=e(3),f=e(\"ee\").get(\"tracer\"),c=e(\"loader\"),s=NREUM;\"undefined\"==typeof window.newrelic&&(newrelic=s);var p=\n",
    "```\n",
    "\n",
    "Стало намного лучше, не правда ли? Что же лежит в переменной `soup`? Невнимательный пользователь, скорее всего, скажет,что ничего вообще не изменилось. Тем не менее, это не так. Теперь мы можем свободно бродить по HTML-дереву страницы, искать детей, родителей и вытаскивать их! \n",
    "\n",
    "Например, можно бродить по вершинам, указывая путь из тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>All Entries | Know Your Meme</title>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.head.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно вытащить из того места, куда мы забрели, текст с помощью метода `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All Entries | Know Your Meme'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.head.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более того, зная адрес элемента, мы сразу можем найти его. Например, можно сделать это по классу. Следующая команда должна найти элемент, который лежит внутри тега `a` и имеет класс `photo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"photo left\" href=\"/memes/events/al-franken-sexual-misconduct-allegations\" target=\"_self\"><img alt=\"Al Franken Accused Of Sexual Misconduct\" data-src=\"http://i0.kym-cdn.com/featured_items/icons/wide/000/007/402/Screen_Shot_2017-11-16_at_2.00.18_PM.png\" height=\"112\" src=\"http://a.kym-cdn.com/assets/blank-b3f96f160b75b1b49b426754ba188fe8.gif\" title=\"Al Franken Accused Of Sexual Misconduct\" width=\"198\"/> <div class=\"info abs\"> <div class=\"c\"> Al Franken Accused Of Sexual Misconduct </div> </div> </a>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = soup.find('a', attrs = {'class':'photo'})\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, вопреки нашим ожиданиям, вытащенный объект имеет класс `\"photo left\"`. Оказывается, `BeautifulSoup4` расценивает аттрибуты `class` как набор отдельных значений, поэтому `\"photo left\"` для библиотеки равносильно `[\"photo\", \"left\"]`, а указанное нами значение этого класса `\"photo\"` входит в этот список. Чтобы избежать такой неприятной ситуации и проходов по ненужным нам ссылкам, придется воспользоваться собственной функцией и задать строгое соответствие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"photo\" href=\"/memes/eas-new-handheld-console\"><img alt=\"EA's new handheld console\" data-src=\"http://i0.kym-cdn.com/entries/icons/medium/000/024/689/Capture.JPG\" src=\"http://a.kym-cdn.com/assets/blank-b3f96f160b75b1b49b426754ba188fe8.gif\" title=\"EA's new handheld console\"/> <div class=\"entry-labels\"> <span class=\"label label-deadpool\"> Deadpool </span> </div> </a>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = soup.find(lambda tag: tag.name == 'a' and tag.get('class') == ['photo'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный после поиска объект также обладает структурой bs4. Поэтому можно продолжить искать нужные нам объекты уже в нём! Вытащим ссылку на этот мем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/memes/eas-new-handheld-console'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.attrs['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что после всех этих безумных преобразований у данных поменялся тип. Теперь они `str`. Это означет, что с ними можно работать как с текстом и пускать в ход для отсеивания лишней информации регулярные выражения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип данных до вытаскивания ссылки: <class 'bs4.element.Tag'>\n",
      "Тип данных после вытаскивания ссылки: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Тип данных до вытаскивания ссылки:\", type(obj))\n",
    "print(\"Тип данных после вытаскивания ссылки:\", type(obj.attrs['href']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если несколько элементов на странице обладают указанным адресом, то метод `find` вернёт только самый первый.  Чтобы найти все элементы с таким адресом, нужно использовать метод `findAll`. На выход будет выдан список! Таким образом, мы можем получить одним поиском сразу все объекты, содержащие ссылки на страницы с мемами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"photo\" href=\"/memes/eas-new-handheld-console\"><img alt=\"EA's new handheld console\" data-src=\"http://i0.kym-cdn.com/entries/icons/medium/000/024/689/Capture.JPG\" src=\"http://a.kym-cdn.com/assets/blank-b3f96f160b75b1b49b426754ba188fe8.gif\" title=\"EA's new handheld console\"/> <div class=\"entry-labels\"> <span class=\"label label-deadpool\"> Deadpool </span> </div> </a>,\n",
       " <a class=\"photo\" href=\"/memes/7-days-7-photos\"><img alt=\"7 Days, 7 Photos\" data-src=\"http://i0.kym-cdn.com/entries/icons/medium/000/024/688/7days.jpg\" src=\"http://a.kym-cdn.com/assets/blank-b3f96f160b75b1b49b426754ba188fe8.gif\" title=\"7 Days, 7 Photos\"/> <div class=\"entry-labels\"> <span class=\"label label-submission\"> Submission </span> </div> </a>,\n",
       " <a class=\"photo\" href=\"/memes/pope-francis-signs-a-lamborghini\"><img alt=\"Pope Francis Signs a Lamborghini\" data-src=\"http://i0.kym-cdn.com/entries/icons/medium/000/024/687/pope.jpg\" src=\"http://a.kym-cdn.com/assets/blank-b3f96f160b75b1b49b426754ba188fe8.gif\" title=\"Pope Francis Signs a Lamborghini\"/> <div class=\"entry-labels\"> <span class=\"label label-submission\"> Submission </span> </div> </a>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_links = soup.findAll(lambda tag: tag.name == 'a' and tag.get('class') == ['photo'])\n",
    "meme_links[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось очистить полученный список от мусора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meme_links = [link.attrs['href'] for link in meme_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/memes/eas-new-handheld-console',\n",
       " '/memes/7-days-7-photos',\n",
       " '/memes/pope-francis-signs-a-lamborghini',\n",
       " '/memes/subcultures/justice-league',\n",
       " '/memes/travis-scotts-concert-pic',\n",
       " '/memes/events/sylvester-stallone-sexual-assault-allegation',\n",
       " '/memes/dilly-dilly',\n",
       " '/memes/%F0%9F%91%89%F0%9F%98%8E%F0%9F%91%89-zoop',\n",
       " '/memes/follow-me-to',\n",
       " '/memes/events/fuck-trump-truck-decal']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meme_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово, получили ровно 16 ссылок по числу мемов на одной странице поиска. \n",
    "\n",
    "Окей, то, что можно искать элемент по его адресу, конечно же, круто, но откуда взять этот адрес? \n",
    "\n",
    "Можно установить для своего браузера какую-нибудь утилиту, позволяющую вытаскивать со страницы нужные теги. Например, [selectorgadget.](http://selectorgadget.com/)\n",
    "\n",
    "Тем не менее, это путь не истинного самурая. Для последователей бусидо есть другой способ — искать теги для каждого нужного нам элемента вручную. Для этого нам придётся жать правой кнопкой мышки по окошечку браузера и тыкать кнопку **Inspect**. Ваше окно браузера будет после всех этих манипуляций выглядеть как-то вот так: \n",
    "\n",
    "<img align=\"center\" src=\"pictures/memes_inspection.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "Если тыкнуть кнопочку, которая находится в огромном красном кружочке, а после навести курсорчик на требующийся вам кусочек странички и тыкнуть на него, то справа, там, где находится гигантская стрелочка, выскочит кусок html-кода, в котором находится адрес выбранного вами объекта. Этот адрес можно смело копировать в свой код и наслаждаться своей брутальностью. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, обернем в красивую функцию все-все манипуляции, проделанные выше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPageLinks(page_number):\n",
    "    \"\"\"\n",
    "        Возвращает список ссылок на мемы, полученный с текущей страницы\n",
    "        \n",
    "        page_number: int/string\n",
    "            номер страницы для парсинга\n",
    "    \"\"\"\n",
    "    # составляем ссылку на страницу поиска\n",
    "    page_link = 'http://knowyourmeme.com/memes/all/page/{}'.format(page_number)\n",
    "    \n",
    "    # запрашиваем данные по ней\n",
    "    response = requests.get(page_link, headers={'User-Agent': UserAgent().chrome})\n",
    "    \n",
    "    if not response.ok:\n",
    "        # если сервер нам отказал, вернем пустой лист для текущей страницы\n",
    "        return [] \n",
    "    \n",
    "    # получаем содержимое страницы и переводим в суп\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "    # наконец, ищем ссылки на мемы и очищаем их от ненужных тэгов\n",
    "    meme_links = soup.findAll(lambda tag: tag.name == 'a' and tag.get('class') == ['photo'])\n",
    "    meme_links = [link.attrs['href'] for link in meme_links]\n",
    "    \n",
    "    return meme_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем функцию и убедимся, что всё хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/memes/eas-new-handheld-console', '/memes/7-days-7-photos']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_links = getPageLinks(1)\n",
    "meme_links[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/memes/people/baked-alaska', '/memes/events/lil-peeps-death']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_links = getPageLinks(2)\n",
    "meme_links[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, функция работает и теперь мы теоретически можем достать ссылки на все 17 171 мем, для чего нам придется пройтись по 17 171 / 16 ~ 1074 страницам. Прежде чем расстраивать сервер таким количеством запросов, посмотрим, как доставать всю необходимую информацию о конкретном меме. А в качестве примера возьмем самый популярный на этом сайте мем - Doge, набравший более 12 миллионов просмотров по состоянию на 18 ноября 2017 года. \n",
    "\n",
    "Сама страница, с которой мы будем доставать дорогую нашему исследовательскому сердцу информацию о меме выглядит следуюшим образом:\n",
    "\n",
    "<img align=\"center\" src=\"pictures/doge_main.png\" height=\"600\" width=\"600\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
